{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import metrics\n",
    "import scipy as sp\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "advertiserlist_path = '../data/adtech_intern_advertiserlist.csv'\n",
    "log_path = '../data/intern_samplelog.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "advertiserlist = pd.read_csv(advertiserlist_path)\n",
    "log_original = pd.read_csv(log_path)\n",
    "log = log_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kei/penv2/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/kei/penv2/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "log.loc[:,'os'][log.os=='iOS'] = 0\n",
    "log.loc[:,'os'][log.os=='Android'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hashnum(modnum, data):\n",
    "    mod = 10 ** modnum\n",
    "    return hash(data) % mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ad_num = 10\n",
    "logEachAd = [log[log.advertiser==ad].drop('advertiser', axis=1)for ad in xrange(1, ad_num + 1)]\n",
    "input_type='string'\n",
    "param_distributions={'learning_rate': [0.1],\n",
    "                     'max_depth': sp.stats.randint(1,11),}\n",
    "                     # 'subsample': sp.stats.uniform(0.5,0.5),\n",
    "                     # 'colsample_bytree': sp.stats.uniform(0.5,0.5),\n",
    "                    # \"min_child_weight\" :  sp.stats.uniform(1, 10),\n",
    "                    # 'gamma' : sp.stats.uniform(0, 1),\n",
    "                    # \"colsample_bytree\" : sp.stats.uniform(0.5, 1)}\n",
    "\n",
    "num_round = 2\n",
    "modnum = 3\n",
    "n_folds = 10\n",
    "\n",
    "xgb_models = [0] * 10\n",
    "aucs = [0] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- mod 10 ** 3  Advertiser 1 -------------------\n",
      "0.59601645\n",
      "----------------- mod 10 ** 3  Advertiser 2 -------------------\n",
      "0.54192745\n",
      "----------------- mod 10 ** 3  Advertiser 3 -------------------\n",
      "0.600247\n",
      "----------------- mod 10 ** 3  Advertiser 4 -------------------\n",
      "0.54961005\n",
      "----------------- mod 10 ** 3  Advertiser 5 -------------------\n",
      "0.54580195\n",
      "----------------- mod 10 ** 3  Advertiser 6 -------------------\n",
      "0.5390913\n",
      "----------------- mod 10 ** 3  Advertiser 7 -------------------\n",
      "0.59278085\n",
      "----------------- mod 10 ** 3  Advertiser 8 -------------------\n",
      "0.5775582\n",
      "----------------- mod 10 ** 3  Advertiser 9 -------------------\n",
      "0.60163455\n",
      "----------------- mod 10 ** 3  Advertiser 10 -------------------\n",
      "0.72033325\n",
      "{'subsample': 0.5, 'eta': 1, 'colsample_bytree': 0.5, 'silent': 1, 'objective': 'binary:logistic', 'gamma': 0, 'max_depth': 9, 'min_child_weight': 1}\n",
      "0.586500105\n"
     ]
    }
   ],
   "source": [
    "param = {'eta':1, 'silent':1, 'objective':'binary:logistic',\n",
    "         'max_depth':9, 'subsample': 0.5,'colsample_bytree': 0.5,\n",
    "         \"min_child_weight\" : 1, 'gamma' : 0, \"colsample_bytree\" : 0.5}\n",
    "for ind, eachlog in enumerate(logEachAd):\n",
    "    print '----------------- mod 10 ** %d  Advertiser %d -------------------' %(modnum, ind+1)\n",
    "    log_data = eachlog.drop('click', axis=1).fillna(0)\n",
    "    log_target = eachlog.click\n",
    "    hashlog_data = [[hashnum(modnum, num) for num in sample] for sample in log_data.drop(['floor_price','os'], axis=1).values]\n",
    "    log_data = np.c_[hashlog_data,log_data.os, log_data.floor_price]\n",
    "    dlog = xgb.DMatrix(log_data,label=log_target)\n",
    "    aucs[ind] = xgb.cv(param, dlog, num_round, nfold=n_folds, metrics={'auc'}, seed = 0)['test-auc-mean'].mean()\n",
    "    print aucs[ind].mean()\n",
    "print param\n",
    "print np.mean(aucs)\n",
    "    # xgb_model = xgb.train(param, dlog, num_round)\n",
    "    # model_path = '../models/Ad%d_xgb.pkl'%(ind+1)\n",
    "    # joblib.dump(xgb_model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- mod 10 ** 3  Advertiser 1 -------------------\n",
      "0.60618805\n",
      "----------------- mod 10 ** 3  Advertiser 2 -------------------\n",
      "0.53056865\n",
      "----------------- mod 10 ** 3  Advertiser 3 -------------------\n",
      "0.586842\n",
      "----------------- mod 10 ** 3  Advertiser 4 -------------------\n",
      "0.54101615\n",
      "----------------- mod 10 ** 3  Advertiser 5 -------------------\n",
      "0.56508595\n",
      "----------------- mod 10 ** 3  Advertiser 6 -------------------\n",
      "0.52313635\n",
      "----------------- mod 10 ** 3  Advertiser 7 -------------------\n",
      "0.5817602\n",
      "----------------- mod 10 ** 3  Advertiser 8 -------------------\n",
      "0.57262495\n",
      "----------------- mod 10 ** 3  Advertiser 9 -------------------\n",
      "0.63359255\n",
      "----------------- mod 10 ** 3  Advertiser 10 -------------------\n",
      "0.6807505\n",
      "{'colsample_bytree': 1, 'silent': 1, 'min_child_weight': 1, 'subsample': 1, 'objective': 'binary:logistic', 'max_depth': 3, 'gamma': 0}\n",
      "0.582156535\n"
     ]
    }
   ],
   "source": [
    "param = {'silent':1, 'objective':'binary:logistic',\n",
    "     'max_depth':3, 'subsample': 1,\"min_child_weight\" : 1, 'gamma' : 0, \"colsample_bytree\" : 1}\n",
    "for ind, eachlog in enumerate(logEachAd):\n",
    "    print '----------------- mod 10 ** %d  Advertiser %d -------------------' %(modnum, ind+1)\n",
    "    log_data = eachlog.drop('click', axis=1).fillna(0)\n",
    "    log_target = eachlog.click\n",
    "    hashlog_data = [[hashnum(modnum, num) for num in sample] for sample in log_data.drop(['floor_price','os'], axis=1).values]\n",
    "    log_data = np.c_[hashlog_data,log_data.os, log_data.floor_price]\n",
    "    dlog = xgb.DMatrix(log_data,label=log_target)\n",
    "    aucs[ind] = xgb.cv(param, dlog, num_round, nfold=n_folds, metrics={'auc'}, seed = 0)['test-auc-mean'].mean()\n",
    "    print aucs[ind].mean()\n",
    "print param\n",
    "print np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- mod 10 ** 3  Advertiser 1 -------------------\n",
      "0.66970785\n",
      "----------------- mod 10 ** 3  Advertiser 2 -------------------\n",
      "0.5703287\n",
      "----------------- mod 10 ** 3  Advertiser 3 -------------------\n",
      "0.6336613\n",
      "----------------- mod 10 ** 3  Advertiser 4 -------------------\n",
      "0.5824795\n",
      "----------------- mod 10 ** 3  Advertiser 5 -------------------\n",
      "0.59906095\n",
      "----------------- mod 10 ** 3  Advertiser 6 -------------------\n",
      "0.55654665\n",
      "----------------- mod 10 ** 3  Advertiser 7 -------------------\n",
      "0.6645466\n",
      "----------------- mod 10 ** 3  Advertiser 8 -------------------\n",
      "0.6675532\n",
      "----------------- mod 10 ** 3  Advertiser 9 -------------------\n",
      "0.71749495\n",
      "----------------- mod 10 ** 3  Advertiser 10 -------------------\n",
      "0.79357065\n",
      "{'colsample_bytree': 1, 'silent': 1, 'min_child_weight': 1, 'subsample': 1, 'objective': 'binary:logistic', 'max_depth': 9, 'gamma': 0}\n",
      "0.645495035\n"
     ]
    }
   ],
   "source": [
    "param = {'silent':1, 'objective':'binary:logistic',\n",
    "     'max_depth':9, 'subsample': 1,\"min_child_weight\" : 1, 'gamma' : 0, \"colsample_bytree\" : 1}\n",
    "for ind, eachlog in enumerate(logEachAd):\n",
    "    print '----------------- mod 10 ** %d  Advertiser %d -------------------' %(modnum, ind+1)\n",
    "    log_data = eachlog.drop('click', axis=1).fillna(0)\n",
    "    log_target = eachlog.click\n",
    "    hashlog_data = [[hashnum(modnum, num) for num in sample] for sample in log_data.drop(['floor_price','os'], axis=1).values]\n",
    "    log_data = np.c_[hashlog_data,log_data.os, log_data.floor_price]\n",
    "    dlog = xgb.DMatrix(log_data,label=log_target)\n",
    "    aucs[ind] = xgb.cv(param, dlog, num_round, nfold=n_folds, metrics={'auc'}, seed = 0)['test-auc-mean'].mean()\n",
    "    print aucs[ind].mean()\n",
    "print param\n",
    "print np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- mod 10 ** 3  Advertiser 1 -------------------\n",
      "0.6701375 0.6802091\n",
      "----------------- mod 10 ** 3  Advertiser 2 -------------------\n",
      "0.5729127 0.59058545\n",
      "----------------- mod 10 ** 3  Advertiser 3 -------------------\n",
      "0.6369728 0.65158765\n",
      "----------------- mod 10 ** 3  Advertiser 4 -------------------\n",
      "0.58541265 0.60729765\n",
      "----------------- mod 10 ** 3  Advertiser 5 -------------------\n",
      "0.59966005 0.6203432\n",
      "----------------- mod 10 ** 3  Advertiser 6 -------------------\n",
      "0.5576448 0.57913425\n",
      "----------------- mod 10 ** 3  Advertiser 7 -------------------\n",
      "0.67648425 0.6888917\n",
      "----------------- mod 10 ** 3  Advertiser 8 -------------------\n",
      "0.6650497 0.6828393\n",
      "----------------- mod 10 ** 3  Advertiser 9 -------------------\n",
      "0.72100465 0.73465175\n",
      "----------------- mod 10 ** 3  Advertiser 10 -------------------\n",
      "0.8018271 0.8107741\n",
      "{'colsample_bytree': 1, 'silent': 1, 'min_child_weight': 1, 'subsample': 1, 'objective': 'binary:logistic', 'max_depth': 11, 'gamma': 0}\n",
      "[ 0.64871062  0.66463141]\n"
     ]
    }
   ],
   "source": [
    "param = {'silent':1, 'objective':'binary:logistic','max_delta_step' = 0,\n",
    "     'max_depth':11, 'subsample': 1,\"min_child_weight\" : 1, 'gamma' : 0, \"colsample_bytree\" : 1}\n",
    "for ind, eachlog in enumerate(logEachAd):\n",
    "    print '----------------- mod 10 ** %d  Advertiser %d -------------------' %(modnum, ind+1)\n",
    "    log_data = eachlog.drop('click', axis=1).fillna(0)\n",
    "    log_target = eachlog.click\n",
    "    hashlog_data = [[hashnum(modnum, num) for num in sample] for sample in log_data.drop(['floor_price','os'], axis=1).values]\n",
    "    log_data = np.c_[hashlog_data,log_data.os, log_data.floor_price]\n",
    "    dlog = xgb.DMatrix(log_data,label=log_target)\n",
    "    aucs[ind] = xgb.cv(param, dlog, num_round, nfold=n_folds, metrics={'auc'}, seed = 0)[['test-auc-mean','train-auc-mean']].mean()\n",
    "    print aucs[ind]['test-auc-mean'], aucs[ind]['train-auc-mean']\n",
    "    xgb_model = xgb.train(param, dlog, num_round)\n",
    "    model_path = '../models/1st_Ad%d_xgb.pkl'%(ind+1)\n",
    "    joblib.dump(xgb_model, model_path)\n",
    "print param\n",
    "print np.mean(np.array(aucs).T, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- mod 10 ** 3  Advertiser 1 -------------------\n",
      "0.66991785 0.68124915\n",
      "----------------- mod 10 ** 3  Advertiser 2 -------------------\n",
      "0.57186485 0.594369\n",
      "----------------- mod 10 ** 3  Advertiser 3 -------------------\n",
      "0.63721185 0.6559841\n",
      "----------------- mod 10 ** 3  Advertiser 4 -------------------\n",
      "0.5866718 0.6123963\n",
      "----------------- mod 10 ** 3  Advertiser 5 -------------------\n",
      "0.6010395 0.62881865\n",
      "----------------- mod 10 ** 3  Advertiser 6 -------------------\n",
      "0.55713405 0.58620975\n",
      "----------------- mod 10 ** 3  Advertiser 7 -------------------\n",
      "0.6753738 0.69292495\n",
      "----------------- mod 10 ** 3  Advertiser 8 -------------------\n",
      "0.6627001 0.68771555\n",
      "----------------- mod 10 ** 3  Advertiser 9 -------------------\n",
      "0.7204414 0.73879895\n",
      "----------------- mod 10 ** 3  Advertiser 10 -------------------\n",
      "0.7990897 0.81151\n",
      "{'subsample': 1, 'gamma': 0, 'colsample_bytree': 1, 'silent': 1, 'objective': 'binary:logistic', 'max_delta_step': 0, 'max_depth': 12, 'min_child_weight': 1}\n",
      "[ 0.64814449  0.66899764]\n"
     ]
    }
   ],
   "source": [
    "param = {'silent':1, 'objective':'binary:logistic','max_delta_step' : 0,\n",
    "     'max_depth':12, 'subsample': 1,\"min_child_weight\" : 1, 'gamma' : 0, \"colsample_bytree\" : 1}\n",
    "for ind, eachlog in enumerate(logEachAd):\n",
    "    print '----------------- mod 10 ** %d  Advertiser %d -------------------' %(modnum, ind+1)\n",
    "    log_data = eachlog.drop('click', axis=1).fillna(0)\n",
    "    log_target = eachlog.click\n",
    "    hashlog_data = [[hashnum(modnum, num) for num in sample] for sample in log_data.drop(['floor_price','os'], axis=1).values]\n",
    "    log_data = np.c_[hashlog_data,log_data.os, log_data.floor_price]\n",
    "    dlog = xgb.DMatrix(log_data,label=log_target)\n",
    "    aucs[ind] = xgb.cv(param, dlog, num_round, nfold=n_folds, metrics={'auc'}, seed = 0)[['test-auc-mean','train-auc-mean']].mean()\n",
    "    print aucs[ind]['test-auc-mean'], aucs[ind]['train-auc-mean']\n",
    "print param\n",
    "print np.mean(np.array(aucs).T, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- mod 10 ** 3  Advertiser 1 -------------------\n",
      "0.66959385 0.68207905\n",
      "----------------- mod 10 ** 3  Advertiser 2 -------------------\n",
      "0.571059 0.5973538\n",
      "----------------- mod 10 ** 3  Advertiser 3 -------------------\n",
      "0.63588375 0.6598904\n",
      "----------------- mod 10 ** 3  Advertiser 4 -------------------\n",
      "0.5866265 0.61941145\n",
      "----------------- mod 10 ** 3  Advertiser 5 -------------------\n",
      "0.59821815 0.6331994\n",
      "----------------- mod 10 ** 3  Advertiser 6 -------------------\n",
      "0.5566885 0.594436\n",
      "----------------- mod 10 ** 3  Advertiser 7 -------------------\n",
      "0.67793595 0.70079575\n",
      "----------------- mod 10 ** 3  Advertiser 8 -------------------\n",
      "0.66010855 0.6935021\n",
      "----------------- mod 10 ** 3  Advertiser 9 -------------------\n",
      "0.7186258 0.74262515\n",
      "----------------- mod 10 ** 3  Advertiser 10 -------------------\n",
      "0.80193805 0.81779615\n",
      "{'subsample': 1, 'gamma': 0, 'colsample_bytree': 1, 'silent': 1, 'objective': 'binary:logistic', 'max_delta_step': 0, 'max_depth': 13, 'min_child_weight': 1}\n",
      "[ 0.64766781  0.67410892]\n"
     ]
    }
   ],
   "source": [
    "param = {'silent':1, 'objective':'binary:logistic','max_delta_step' : 0,\n",
    "     'max_depth':13, 'subsample': 1,\"min_child_weight\" : 1, 'gamma' : 0, \"colsample_bytree\" : 1}\n",
    "for ind, eachlog in enumerate(logEachAd):\n",
    "    print '----------------- mod 10 ** %d  Advertiser %d -------------------' %(modnum, ind+1)\n",
    "    log_data = eachlog.drop('click', axis=1).fillna(0)\n",
    "    log_target = eachlog.click\n",
    "    hashlog_data = [[hashnum(modnum, num) for num in sample] for sample in log_data.drop(['floor_price','os'], axis=1).values]\n",
    "    log_data = np.c_[hashlog_data,log_data.os, log_data.floor_price]\n",
    "    dlog = xgb.DMatrix(log_data,label=log_target)\n",
    "    aucs[ind] = xgb.cv(param, dlog, num_round, nfold=n_folds, metrics={'auc'}, seed = 0)[['test-auc-mean','train-auc-mean']].mean()\n",
    "    print aucs[ind]['test-auc-mean'], aucs[ind]['train-auc-mean']\n",
    "print param\n",
    "print np.mean(np.array(aucs).T, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Advertiser 1 -------------------\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] learning_rate=0.1, max_depth=5 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=5 -   2.7s\n",
      "[CV] learning_rate=0.1, max_depth=5 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=5 -   2.7s\n",
      "[CV] learning_rate=0.1, max_depth=5 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=5 -   2.7s\n",
      "[CV] learning_rate=0.1, max_depth=5 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=5 -   2.7s\n",
      "[CV] learning_rate=0.1, max_depth=5 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=5 -   2.7s\n",
      "[CV] learning_rate=0.1, max_depth=5 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=5 -   2.7s\n",
      "[CV] learning_rate=0.1, max_depth=5 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=5 -   2.7s\n",
      "[CV] learning_rate=0.1, max_depth=5 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=5 -   2.8s\n",
      "[CV] learning_rate=0.1, max_depth=5 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=5 -   2.7s\n",
      "[CV] learning_rate=0.1, max_depth=5 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=5 -   3.0s\n",
      "0.499945934256\n",
      "----------------- Advertiser 2 -------------------\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] learning_rate=0.1, max_depth=9 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=9 -   4.6s\n",
      "[CV] learning_rate=0.1, max_depth=9 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=9 -   6.1s\n",
      "[CV] learning_rate=0.1, max_depth=9 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=9 -   4.8s\n",
      "[CV] learning_rate=0.1, max_depth=9 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=9 -   4.9s\n",
      "[CV] learning_rate=0.1, max_depth=9 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=9 -   5.1s\n",
      "[CV] learning_rate=0.1, max_depth=9 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=9 -   5.2s\n",
      "[CV] learning_rate=0.1, max_depth=9 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=9 -   5.7s\n",
      "[CV] learning_rate=0.1, max_depth=9 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=9 -   5.9s\n",
      "[CV] learning_rate=0.1, max_depth=9 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=9 -   5.3s\n",
      "[CV] learning_rate=0.1, max_depth=9 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=9 -   5.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   27.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   53.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.500493248106\n",
      "----------------- Advertiser 3 -------------------\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] learning_rate=0.1, max_depth=2 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=2 -   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=2 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=2 -   2.1s\n",
      "[CV] learning_rate=0.1, max_depth=2 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=2 -   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=2 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=2 -   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=2 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=2 -   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=2 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=2 -   1.6s\n",
      "[CV] learning_rate=0.1, max_depth=2 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=2 -   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=2 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=2 -   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=2 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=2 -   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=2 ..................................\n",
      "[CV] ......................... learning_rate=0.1, max_depth=2 -   1.4s\n",
      "0.5\n",
      "----------------- Advertiser 4 -------------------\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] learning_rate=0.1, max_depth=9 ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   15.5s finished\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6a5e7f2ae259>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mxgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"roc_auc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kei/penv2/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    994\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m                                           random_state=self.random_state)\n\u001b[0;32m--> 996\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/kei/penv2/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 for train, test in cv)\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kei/penv2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kei/penv2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    660\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kei/penv2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kei/penv2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kei/penv2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kei/penv2/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kei/penv2/lib/python2.7/site-packages/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m    341\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m                               verbose_eval=verbose)\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kei/penv2/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mnboost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kei/penv2/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ind, eachlog in enumerate(logEachAd):\n",
    "    print '----------------- Advertiser %d -------------------' %(ind+1)\n",
    "    log_data = eachlog.drop('click', axis=1)\n",
    "    log_target = eachlog.click.values\n",
    "    hashlog_data = [[hashnum(modnum, num) for num in sample] for sample in log_data.drop(['floor_price','os'], axis=1).values]\n",
    "    log_data = np.c_[hashlog_data,log_data.os]\n",
    "    sample_length = len(log_target)/10\n",
    "    trainX = log_data[:-sample_length]\n",
    "    trainY = log_target[:-sample_length]\n",
    "    testX = log_data[-sample_length:]\n",
    "    testY = log_target[-sample_length:]\n",
    "    # dlog = xgb.DMatrix(log_data, label=log_target)\n",
    "    xgb_model = xgb.XGBClassifier(param)\n",
    "    rs = RandomizedSearchCV(xgb_model, param_distributions, cv=10, n_iter=1, scoring=\"roc_auc\", verbose=2, n_jobs = 1, random_state=0 )\n",
    "    rs.fit(trainX,trainY)\n",
    "    predict = rs.predict(testX)\n",
    "    print roc_auc_score(testY, predict)\n",
    "    best_param = {'learning_rate': rs.best_estimator_.learning_rate,\n",
    "              'max_depth': rs.best_estimator_.max_depth,\n",
    "                 'subsample': rs.best_estimator_.subsample,\n",
    "                  \"min_child_weight\" :  rs.best_estimator_.min_child_weight,\n",
    "              'gamma': rs.best_estimator_.gamma,\n",
    "              'silent': rs.best_estimator_.silent,\n",
    "              'objective': rs.best_estimator_.objective,\n",
    "                  \"colsample_bytree\" : rs.best_estimator_.colsample_bytree\n",
    "              }\n",
    "    dtrain = xgb.DMatrix(log_data, label=log_target)\n",
    "    bst = xgb.train(best_param, dtrain, num_round)\n",
    "    model_path = '../models/Ad%d_xgb.pkl'%(ind+1)\n",
    "    joblib.dump(bst, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs.fit(trainX,trainY)\n",
    "predict = rs.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ind, eachlog in enumerate(logEachAd):\n",
    "    print '----------------- Advertiser %d -------------------' %(ind+1)\n",
    "    log_data = eachlog.drop('click', axis=1)\n",
    "    log_target = eachlog.click.values\n",
    "    hashlog_data = [[hashnum(modnum, num) for num in sample] for sample in log_data.drop(['floor_price','os'], axis=1).values]\n",
    "    log_data = np.c_[hashlog_data,log_data.os]\n",
    "    dlog = xgb.DMatrix(log_data, label=log_target)\n",
    "    xgb_model = xgb.train(param, dlog_train, num_round)\n",
    "    \n",
    "    kf = KFold(len(log_target), n_folds=n_folds, shuffle=True, random_state=0)\n",
    "    for train_index, test_index in kf:\n",
    "        dlog_train = xgb.DMatrix(\n",
    "            log_data[train_index], label=log_target[train_index])\n",
    "        dlog_test = xgb.DMatrix(\n",
    "            log_data[test_index], label=log_target[test_index])\n",
    "        xgb_model = xgb.train(param, dlog_train, num_round)\n",
    "        predict = xgb_model.predict(dlog_test)\n",
    "        # print metrics.roc_auc_score(log_target[test_index], predict)\n",
    "    xgb_models[ind] = xgb.train(param, dlog, num_round)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
